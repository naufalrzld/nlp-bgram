{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk load data corpus dari file txt\n",
    "# Return dari fungsi ini adalah string yang berisi corpus topik tertentu\n",
    "def loadCorpus(file_name):\n",
    "    p = ''\n",
    "    with open(file_name, 'r') as corpus:\n",
    "        for data in corpus:\n",
    "            sentences = data.split('\\t')\n",
    "            p += sentences[0].replace('\\n', ' ')\n",
    "    \n",
    "    return p.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panggil fungsi corpus dan simpan hasilnya ke variable corpus\n",
    "corpus = loadCorpus('plain/minicorpus.txt')\n",
    "# Melakukan tokenisasi corpus\n",
    "token = nltk.word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saya suka makan nasi. saya suka kamu, kamu suka dia. tidur di kasur. kasur tempat untuk tidur. makanan yang saya suka adalah nasi padang. saya makan nasi di warung. warung nasi padang adalah tempat favorit saya. makanan di warung nasi padang yang sangat saya suka yaitu nasi rendang. rasanya sangat enak. makanan kesukaan saya selain rendang adalah ayam goreng. saya pergi ke toko buku untuk membeli sebuah buku. buku yang saya beli berwarna biru. buku biru itu adalah milik saya.\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saya', 'suka', 'makan', 'nasi', '.', 'saya', 'suka', 'kamu', ',', 'kamu', 'suka', 'dia', '.', 'tidur', 'di', 'kasur', '.', 'kasur', 'tempat', 'untuk', 'tidur', '.', 'makanan', 'yang', 'saya', 'suka', 'adalah', 'nasi', 'padang', '.', 'saya', 'makan', 'nasi', 'di', 'warung', '.', 'warung', 'nasi', 'padang', 'adalah', 'tempat', 'favorit', 'saya', '.', 'makanan', 'di', 'warung', 'nasi', 'padang', 'yang', 'sangat', 'saya', 'suka', 'yaitu', 'nasi', 'rendang', '.', 'rasanya', 'sangat', 'enak', '.', 'makanan', 'kesukaan', 'saya', 'selain', 'rendang', 'adalah', 'ayam', 'goreng', '.', 'saya', 'pergi', 'ke', 'toko', 'buku', 'untuk', 'membeli', 'sebuah', 'buku', '.', 'buku', 'yang', 'saya', 'beli', 'berwarna', 'biru', '.', 'buku', 'biru', 'itu', 'adalah', 'milik', 'saya', '.']\n"
     ]
    }
   ],
   "source": [
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membuat model unigram\n",
    "# Return dari fungsi ini yaitu dictionary yang berisi unigram dari kata yang ada dalam corpus\n",
    "def unigram(corpus):\n",
    "    a = {}\n",
    "    for word in token:\n",
    "        if word not in a:\n",
    "            a[word] = 1\n",
    "        else:\n",
    "            a[word] += 1\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat unigram dari corpus yang sudah di load kemudian disimpan kedalam variable ugram\n",
    "ugram = unigram(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'saya': 10, 'suka': 5, 'makan': 2, 'nasi': 6, '.': 13, 'kamu': 2, ',': 1, 'dia': 1, 'tidur': 2, 'di': 3, 'kasur': 2, 'tempat': 2, 'untuk': 2, 'makanan': 3, 'yang': 3, 'adalah': 4, 'padang': 3, 'warung': 3, 'favorit': 1, 'sangat': 2, 'yaitu': 1, 'rendang': 2, 'rasanya': 1, 'enak': 1, 'kesukaan': 1, 'selain': 1, 'ayam': 1, 'goreng': 1, 'pergi': 1, 'ke': 1, 'toko': 1, 'buku': 4, 'membeli': 1, 'sebuah': 1, 'beli': 1, 'berwarna': 1, 'biru': 2, 'itu': 1, 'milik': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ugram)\n",
    "len(ugram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan unigram terhadap token yang sudah diinisialisasi\n",
    "# Tujuannya untuk mendapatkan kata-kata yang unik dari corpus yang ada\n",
    "token_unigram = []\n",
    "\n",
    "for word in token:\n",
    "    if (word not in token_unigram):\n",
    "        token_unigram.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi bgram dengan jumlah setiap pasangan kata adalah 0\n",
    "dict_bgram = {}\n",
    "for word_x in token_unigram:\n",
    "    a = {}\n",
    "    for word_y in token_unigram:\n",
    "        a[word_y] = 0\n",
    "        \n",
    "    dict_bgram[word_x] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update table bgram jika menemukan pasangan kata yang sesuai di dalam corpus\n",
    "# Jika pasangan kata ditemukan maka jumlah pasangan kata tersebut bertambah\n",
    "token = np.array(token)\n",
    "for word in token_unigram:\n",
    "    # Mencari index dari kata pertama\n",
    "    index = np.where(token == word)\n",
    "    a = []\n",
    "    \n",
    "    # Mencari kata selanjutnya dari kata sebelumnya (word[i+1])\n",
    "    # Kemudian simpan ke dalam array\n",
    "    for i in index[0]:\n",
    "        if (i+1 != len(token)):\n",
    "            a.append(token[i+1])\n",
    "    \n",
    "    # Menjumlahkan kata yang sudah ada di table bgram jika menemukan pasangan kata yang serupa\n",
    "    for word2 in a:\n",
    "        dict_bgram[word][word2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung peluang table bgram\n",
    "def calculate_prob_bgram(dict_bgram, ugram):\n",
    "    a = {}\n",
    "    for word1 in dict_bgram:\n",
    "        b = {}\n",
    "        for word2 in dict_bgram[word1]:\n",
    "            b[word2] = dict_bgram[word1][word2]/ugram[word1]\n",
    "        a[word1] = b\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_prob_bgram = calculate_prob_bgram(dict_bgram, ugram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan file bgram dalam format json\n",
    "with open('bgram.json', 'w') as f:\n",
    "    json.dump(dict_prob_bgram, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Input Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung probabilitas dari kalimat berdasarkan model bgram\n",
    "def calculate_prob_input(dict_prob_bgram, kalimat_input):\n",
    "    hasil = 1\n",
    "    for i in range(len(kalimat_input)-1):\n",
    "        word = kalimat_input\n",
    "        if (word[i] in dict_prob_bgram.keys() and word[i+1] in dict_prob_bgram.keys()):\n",
    "            hasil *= dict_prob_bgram[word[i]][word[i+1]]\n",
    "        else: \n",
    "            hasil *= 0\n",
    "            break\n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memprediksi kata selanjutnya yang mungkin dan memiliki probabilitas yang besar\n",
    "def predict_best_prob(dict_prob_bgram, kalimat_input):\n",
    "    newKalimat = kalimat_input\n",
    "    for i in range(len(kalimat_input)-1):\n",
    "        currWord = kalimat_input[i]\n",
    "        nextWord = kalimat_input[i+1]\n",
    "        if (currWord in dict_prob_bgram.keys() and nextWord in dict_prob_bgram.keys()):\n",
    "            a = [k for k, v in dict_prob_bgram[currWord].items() if v == max(dict_prob_bgram[currWord].values())]\n",
    "            if (nextWord not in a):\n",
    "                nextWord = a[0]\n",
    "            newKalimat[i+1] = nextWord\n",
    "        else:\n",
    "            print('Kata ', currWord, ' tidak ada di dalam corpus')\n",
    "            \n",
    "    return newKalimat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk mengambil data kamus\n",
    "def loadKamus():\n",
    "    a = []\n",
    "    with open('english_indonesia.txt', 'r') as kamus:\n",
    "        for data in kamus:\n",
    "            k = data.split('\\t')\n",
    "            token_arti = nltk.word_tokenize(k[1])\n",
    "            a.append([k[0], token_arti])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk membersihkan kamus dari karakter yang tidak diperlukan\n",
    "# Fungsi ini mengembalikan 1 kata pertama terjemahan bahasa inggris - indonesia\n",
    "def clearKamus(kamus):\n",
    "    a = {}\n",
    "    b = ['ks', 'kt', 'kb', 'kkt', 'ks', 'kki', 'kk', 'kb..', 'ks.', 'kg', '.', '(', ')', \n",
    "         '1', '2', '3', '4', '5', '.1', 'kb1.', '[', ']', ',']\n",
    "    for data in kamus:\n",
    "        bb = [elm for elm in data[1] if elm not in b]\n",
    "        a[data[0]] = bb[0]\n",
    "        \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kamus = loadKamus()\n",
    "clear_kamus = clearKamus(kamus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(kalimat_input):    \n",
    "    kalimat_input = kalimat_input.lower()\n",
    "    token_kalimat = nltk.word_tokenize(kalimat_input)\n",
    "\n",
    "    terjemahan = []\n",
    "\n",
    "    for kata in token_kalimat:\n",
    "        terjemahan.append(clear_kamus[kata])\n",
    "\n",
    "    print('Kalimat input: ', kalimat_input)\n",
    "    print()\n",
    "    print('Terjemahan: ', terjemahan)\n",
    "    prob = calculate_prob_input(dict_prob_bgram, terjemahan)\n",
    "    print('Probabilitas: ', prob)\n",
    "\n",
    "    newKalimat = predict_best_prob(dict_prob_bgram, terjemahan)\n",
    "    print()\n",
    "    newProb = calculate_prob_input(dict_prob_bgram, newKalimat)\n",
    "    print('Best Predict: ', newKalimat)\n",
    "    print('Probabilitas: ', newProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat input:  i like you\n",
      "\n",
      "Terjemahan:  ['saya', 'kesukaan', 'kamu']\n",
      "Probabilitas:  0.0\n",
      "\n",
      "Best Predict:  ['saya', 'suka', 'kamu']\n",
      "Probabilitas:  0.08000000000000002\n"
     ]
    }
   ],
   "source": [
    "execute('i like you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat input:  i eat rice\n",
      "\n",
      "Terjemahan:  ['saya', 'eats', 'padi']\n",
      "Probabilitas:  0\n",
      "Kata  saya  tidak ada di dalam corpus\n",
      "Kata  eats  tidak ada di dalam corpus\n",
      "\n",
      "Best Predict:  ['saya', 'eats', 'padi']\n",
      "Probabilitas:  0\n"
     ]
    }
   ],
   "source": [
    "execute('i eat rice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat input:  i eat on the bed\n",
      "\n",
      "Terjemahan:  ['saya', 'eats', 'sedang', 'kst', 'tempat']\n",
      "Probabilitas:  0\n",
      "Kata  saya  tidak ada di dalam corpus\n",
      "Kata  eats  tidak ada di dalam corpus\n",
      "Kata  sedang  tidak ada di dalam corpus\n",
      "Kata  kst  tidak ada di dalam corpus\n",
      "\n",
      "Best Predict:  ['saya', 'eats', 'sedang', 'kst', 'tempat']\n",
      "Probabilitas:  0\n"
     ]
    }
   ],
   "source": [
    "execute('i eat on the bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat input:  i sleep in a stall\n",
      "\n",
      "Terjemahan:  ['saya', 'tidur', 'Inf', 'huruf', 'kedai']\n",
      "Probabilitas:  0.0\n",
      "Kata  suka  tidak ada di dalam corpus\n",
      "Kata  Inf  tidak ada di dalam corpus\n",
      "Kata  huruf  tidak ada di dalam corpus\n",
      "\n",
      "Best Predict:  ['saya', 'suka', 'Inf', 'huruf', 'kedai']\n",
      "Probabilitas:  0.0\n"
     ]
    }
   ],
   "source": [
    "execute('i sleep in a stall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kalimat input:  i bought a blue book\n",
      "\n",
      "Terjemahan:  ['saya', 'lih', 'huruf', 'biru', 'buku']\n",
      "Probabilitas:  0\n",
      "Kata  saya  tidak ada di dalam corpus\n",
      "Kata  lih  tidak ada di dalam corpus\n",
      "Kata  huruf  tidak ada di dalam corpus\n",
      "\n",
      "Best Predict:  ['saya', 'lih', 'huruf', 'biru', '.']\n",
      "Probabilitas:  0\n"
     ]
    }
   ],
   "source": [
    "execute('i bought a blue book')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
